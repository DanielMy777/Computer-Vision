{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avengers-Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Avengers Detector**\n",
        "Using transfer learning on a custon dataset to detect the original 6 avengers from a media source.\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "0Lz7KCtVv2vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preperation:**\n",
        "\n",
        "\n",
        "*   Downloading YOLOv3.\n",
        "*   Downloading the dataset.\n",
        "*   Attaching configuration file.\n",
        "*   Downloading and updating required libraries.\n",
        "\n"
      ],
      "metadata": {
        "id": "Vhteo16ewrK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "am0BKbj63u0t"
      },
      "outputs": [],
      "source": [
        "# clean up previous session results.\n",
        "! rm -rf dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading yolov3 and installing its requirements.\n",
        "! git clone https://github.com/ultralytics/yolov3.git\n",
        "! cd yolov3\n",
        "! pip install -r yolov3/requirements.txt"
      ],
      "metadata": {
        "id": "LWoEvsm93z2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# < !!! first, you must sign up to https://www.kaggle.com/, retrieve an api key, \n",
        "# and place it in the home dir of the session !!! more info on => https://www.kaggle.com/general/51898 >\n",
        "\n",
        "# install kaggle.\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Xt3uehTS36GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the avengers dataset from kaggle.\n",
        "! kaggle datasets download Avengers-Dataset\n",
        "! unzip Avengers-Dataset.zip\n",
        "! mkdir dataset\n",
        "! mv images dataset\n",
        "! mv labels dataset"
      ],
      "metadata": {
        "id": "DXOTXjYS38Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the custom configuration file to the yolov3 data folder.\n",
        "! cp avengers.yaml yolov3/data"
      ],
      "metadata": {
        "id": "AMofmJWp4ADx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install required versions of albumentations and opencv.\n",
        "# (press 'yes' / 'y' when asked)\n",
        "! pip uninstall albumentations\n",
        "! pip install albumentations\n",
        "! pip uninstall opencv-python-headless \n",
        "! pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "id": "NTHKsRxJ4C5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Augumentation:**\n",
        "\n",
        "The code below taked every image from the 'train' folder and passes it through 3 random transformations. A new image and annotations file will be created and saved as another piece of data to train on."
      ],
      "metadata": {
        "id": "aUmdOofczV8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "save_path = \"dataset/images/train/\"\n",
        "generated = 1\n",
        "\n",
        "transform1 = A.Compose([\n",
        "    A.RandomCrop(width=100, height=100),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "], bbox_params=A.BboxParams(format='yolo', min_visibility=0.5))\n",
        "\n",
        "transform2 = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.3),\n",
        "        A.RGBShift(r_shift_limit=30, g_shift_limit=30, b_shift_limit=30, p=0.3),\n",
        "    ],\n",
        "    bbox_params=A.BboxParams(format='yolo', min_visibility=0.5))\n",
        "\n",
        "transform3 = A.Compose(\n",
        "    [A.CenterCrop(height=100, width=100, p=1)],\n",
        "    bbox_params=A.BboxParams(format='yolo', min_area=4500, min_visibility=0.5),\n",
        ")\n",
        "\n",
        "def save_transform(image, bbox, transformation):\n",
        "  global generated\n",
        "  lines = []\n",
        "  pic_path = save_path + \"gen\" +  str(generated) + \".jpg\"\n",
        "  label_path = pic_path[:-3] + \"txt\"\n",
        "  label_path = label_path.replace(\"images\", \"labels\")\n",
        "  transformed = transformation(image=image, bboxes=bbox)\n",
        "  transformed_image = transformed['image']\n",
        "  transformed_bboxes = transformed['bboxes']\n",
        "  cv2.imwrite(pic_path, transformed_image)\n",
        "  for bbox in transformed_bboxes:\n",
        "    lines.append(f\"{bbox[4]} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")\n",
        "  with open(label_path, 'w') as f:\n",
        "    f.writelines(lines)\n",
        "  generated += 1\n",
        "\n",
        "\n",
        "for pic_path in glob.iglob(save_path + '*.jpg'):\n",
        "    bbox = []\n",
        "    image = cv2.imread(pic_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    label_path = pic_path[:-3] + \"txt\"\n",
        "    label_path = label_path.replace(\"images\", \"labels\", 1)\n",
        "    with open(label_path, \"r\") as label_file:\n",
        "      for line in label_file:\n",
        "        line = line.strip()\n",
        "        data = line.split()\n",
        "        bbox.append([float(data[1]), float(data[2]), float(data[3]), float(data[4]), data[0]])\n",
        "    save_transform(image.copy(), bbox, transform1)\n",
        "    save_transform(image.copy(), bbox, transform2)\n",
        "    save_transform(image.copy(), bbox, transform3)"
      ],
      "metadata": {
        "id": "P-IHGbxs4D2Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traning:**\n",
        "\n",
        "Beginning the training process with the following parameters:\n",
        "\n",
        "\n",
        "*   *freeze* => how many modules to freeze and not re-train.  (we picked 10, which is all the backcone layers, 53 layers in total will be frozen. pick 24 in order to train only the last layer, worse results tho)\n",
        "*   *img* => size of the images we will train on.\n",
        "*   *batch* => batch size of the images we will train on. (depends on GPU strength)\n",
        "*   *epoches* => number of epochs to conclude. (around 30 is enough)\n",
        "*   *data* => configuration file name. (mentioned above)\n",
        "*   *weights* => making use of pre-trained weights for the frozen layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Uu-LhVUz8Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete all previous training result and begin the training process.\n",
        "# results will be saved in yolov3/runs/train/exp and will consist of the new weights.\n",
        "# (press (3) - dont visualize my results when asked)\n",
        "! rm -rf yolov3/runs/train\n",
        "! python yolov3/train.py --freeze 10 --img 256 --batch 16 --epochs 100 --data avengers.yaml --weights yolov3.pt"
      ],
      "metadata": {
        "id": "NX8DAai94KUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing:**\n",
        "\n",
        "Testing our newly trained machine on the test set with the following parameters:\n",
        "\n",
        "\n",
        "*   *weights* => the trained weights to use for the detection. (we use the best ones we obtained from our trainig process)\n",
        "*   *data* => configuration file.\n",
        "*   *img* => size of the images to test on.\n",
        "*   *task* => which task to apply, 'test' is configured in the configuration file and has the path to the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "0AIdu80U1sas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove any previous results.\n",
        "# begin the testing process with our newly trained weights.\n",
        "# results will be saved in yolov3/runs/val/exp.\n",
        "! rm best.pt\n",
        "! cp yolov3/runs/train/exp/weights/best.pt .\n",
        "! rm -rf yolov3/runs/val\n",
        "! python yolov3/val.py --weights best.pt --data avengers.yaml --img 256 --task test"
      ],
      "metadata": {
        "id": "7cbRsFIJ4OeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result:**\n",
        "\n",
        "After the test on the test-set was OK, we will now test detection on a desired video.\n",
        "\n",
        "A video named input.mp4 has to be uploaded to the home dir of the session and only then the cell can run.\n",
        "\n",
        "to begin the detection we use the following parameters:\n",
        "\n",
        "\n",
        "*   *weights* => the trained weights to use for the detection. (we use the best ones we obtained from our trainig process)\n",
        "*   *imgsz* => adjusted to recieve maximal results. (most likely will be the image size trained on)\n",
        "*   *conf* => minimal confidence to consider as a detection.\n",
        "*   *source* => path to the media source.\n",
        "*   *hide-conf* => do not show confidence probabilities in the output video.\n",
        "\n"
      ],
      "metadata": {
        "id": "1IWScq7p28fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# < !!! a file named 'input.mp4' has to be uploaded to the home dir of the session (drag & drop) !!! >\n",
        "# remove any previous results and begin detection.\n",
        "# restults will be in the 'res' folder.\n",
        "! rm -rf res\n",
        "! rm -rf yolov3/runs/detect\n",
        "! python yolov3/detect.py --weights best.pt --imgsz 256 --conf 0.55 --source input.mp4 --hide-conf\n",
        "! cp -r yolov3/runs/detect/exp ./res"
      ],
      "metadata": {
        "id": "Nzt3MKWT4YzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}